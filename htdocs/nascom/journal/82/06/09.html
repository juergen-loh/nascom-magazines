<?php columnStartJustify(2, 2); ?>

<h1 id="article1">
ROBOT-Intelligence
</h1>
<h3>
von Günter Böhm
</h3>
<p>
Da ich mir jede Veröffentlichung über Roboter anschaffe, kam mir nun auch das Buch
&bdquo;<?php externalLink("ROBOT INTELLIGENCE with experiments","",""); ?>&ldquo; von
<?php externalLink("David L. Heiserman"); ?>
unter die Finger (TAB BOOKS INC vertrieben von
Hofacker Verlag). Das Buch unterscheidet sich von anderen Werken des Authors
dadurch, daß es sich nicht mit dem Bau und der Programmierung von
beweglichen Maschinen beschäftigt, sondern mit der Simulation von
&bdquo;Maschinenintelligenz&ldquo; am Bildschirm eines Rechners. Dies
macht für einen größeren Leserkreis interessant. Die vielen
Beispielprogramme sind für den
<?php externalLink("TRS-80","TRS&nbsp;80"); ?> geschrieben, lassen sich aber,
wie die abgedruckten Beispiele zeigen, relativ leicht an den <span class="uppercase">Nascom</span>
anpassen.
</p>
<p>
Heiserman sieht die Haupteigenschaft eines Roboters in der
Fähigkeit, sich neuen Situationen anzupassen. So ist für ihn ein
sogenannter Industrie-Roboter kein wirklicher Roboter, da er nur
vorprogrammierte Schritte ausführt und nicht umlernen kann, wenn neue
Situationen auftauchen. Sein Ziel ist die Konstruktion einer Maschine,
die sich selbst programmiert.
</p>
<p>
Dieses Ziel will er durch die Entwicklung
eines &bdquo;Programmes&ldquo; erreichen, das er EAMI (Evolutionary
Adaptive Machine Intelligence) nennt, also ein Programm, das sich
entwickelt und anpaßt. Die Entwicklung des Programmes (die noch lange
nicht abgeschlossen ist, und zu deren Heiterführung der Leser
aufgefordert wird &ndash; Sie kennen so etwas ja aus dem Journal), wird sehr
anschaulich beschrieben (leider alles in Englisch) und an Unmengen von
Programmen verdeutlicht.
</p>
<p>
Hier ein kurzer Abriß des Aufbaus:
</p>
<p>
Heiserman
teilt seine &bdquo;Intelligenzen&ldquo; in Alpha-, Beta- und Gamma-Wesen
ein, jeweils Level (Niveau) I oder II. Die Alphawesen existieren nur in
der Gegenwart und reagieren rein zufällig. Auf dem Bildschirm wird das
simuliert, indem ein &bdquo;Wesen&ldquo; (in unserem Beispiel das
Bell-Zeichen) sich innerhalb eines rechteckigen
&bdquo;Spielfeldes&ldquo; bewegt. Würde bei der nächsten Bewegung der
Feldrand berührt (Contact), so muß eine Bewegungsrichtung gefunden
werden, die dies vermeidet. Aus 24 möglichen Richtungen wird per
</p>

<?php columnChangeJustify(2); ?>

<p>
<?php imageInsertJrn("Image-09-1.jpeg"); ?>
</p>
<p>
Zufall eine ausgewählt. Über dem Spielfeld werden die Kontakte, die
erfolgreichen Bewegungen (vom Rand weg) und deren Verhältnis (Score)
angezeigt. Wieoft man auch die Simulation durch Drücken der D-Taste neu
startet (D=disturb=stören), das Alpha-Wesen wird immer eine
erfolgsquote von 0.5 und knapp darunter erreichen.
</p>
<p>
Das Beta-Wesen merkt sich die erfolgreichen Bewegungen und setzt sie in
gleichen Situationen wieder ein. Es &bdquo;lebt&ldquo; also in Gegenwart
und Vergangenheit. Es beginnt seine Bewegung auch erst rein zufällig,
nach gewisser Zeit bemerkt man aber, daß es sich ein bestimmtes
&bdquo;Verhaltensmuster&ldquo; aneignet: seine Bewegungen verlaufen nach
dem gleichen
</p>
<p>
<?php imageInsertJrn("Image-09-2.jpeg"); ?>
</p>

<?php columnEnd(2); ?>
